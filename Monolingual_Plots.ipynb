{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.spatial.distance import cdist\n",
    "import importlib\n",
    "\n",
    "def get_distances(x1: list, y1: list, x2: list, y2: list, labels: list):\n",
    "    distances = []\n",
    "    for i, emotion in enumerate(labels):\n",
    "        dist = cdist([[x1[i], y1[i]]], [[x2[i], y2[i]]], 'euclidean')[0][0]\n",
    "        print(\"%s: %f\" % (emotion, dist))\n",
    "        distances.append(dist)\n",
    "    print(\"Average distance between points: %f\" % (np.mean(distances)))\n",
    "\n",
    "def get_averaged_points(emotion_encoding, x, y):\n",
    "    unique_emotions_x = {}\n",
    "    unique_emotions_y = {}\n",
    "    for i in range(len(emotion_encoding.category_list)):\n",
    "        emotion = emotion_encoding.category_list[i]\n",
    "        if emotion not in unique_emotions_x:\n",
    "            unique_emotions_x[emotion] = []\n",
    "            unique_emotions_y[emotion] = []\n",
    "        unique_emotions_x[emotion].append(x[i])\n",
    "        unique_emotions_y[emotion].append(y[i])\n",
    "\n",
    "    emotion_labels = list(unique_emotions_x.keys())\n",
    "    x_avg = []\n",
    "    y_avg = []\n",
    "    for emotion in emotion_labels:\n",
    "        x_avg.append(np.mean(unique_emotions_x[emotion]))\n",
    "        y_avg.append(np.mean(unique_emotions_y[emotion]))\n",
    "    return x_avg, y_avg, emotion_labels\n",
    "\n",
    "def make_plot(axis_file: str, \n",
    "              emotion_file: str, \n",
    "              x_category_high: str, \n",
    "              x_category_low: str, \n",
    "              y_category_high: str, \n",
    "              y_category_low: str, \n",
    "              encoding_mode: str, \n",
    "              plot_labels: list, #[title, x_label, y_label]\n",
    "              return_points=False, #[[x_points], [y_points], [emotion labels]]\n",
    "              roberta_model_name=None,\n",
    "              sent_model_name=None,\n",
    "              emotion_filepath=None):\n",
    "    if(encoding_mode == 'roberta' and roberta_model_name is None):\n",
    "        raise ValueError(\"provide a roberta model name\")\n",
    "\n",
    "    if(encoding_mode == 'sentence_transformers' and sent_model_name is None):\n",
    "        raise ValueError(\"provide a sentence transformer model name\")\n",
    "    \n",
    "    # Define dimensions and get encodings\n",
    "    axis_dimensions = utils.Emotion_Category(axis_file, roberta_model_name=roberta_model_name, sent_model_name=sent_model_name)\n",
    "    axis_dimensions.contextualization(\"\", official=False)\n",
    "    axis_dimensions.new_encoding(mode=encoding_mode, mean_centered=False, official=False)\n",
    "    \n",
    "    # Define and create axes\n",
    "    X_high = utils.generate_averaged_points(category=x_category_high, mode=encoding_mode, official=False, args=[axis_dimensions])\n",
    "    X_low = utils.generate_averaged_points(category=x_category_low, mode=encoding_mode, official=False, args=[axis_dimensions])\n",
    "    Y_high = utils.generate_averaged_points(category=y_category_high, mode=encoding_mode, official=False, args=[axis_dimensions])\n",
    "    Y_low = utils.generate_averaged_points(category=y_category_low, mode=encoding_mode, official=False, args=[axis_dimensions])\n",
    "\n",
    "    # Encode emotions to plot\n",
    "    emotion_encoding = utils.Emotion_Category(emotion_file, roberta_model_name=roberta_model_name, sent_model_name=sent_model_name, filepath=emotion_filepath)\n",
    "    emotion_encoding.contextualization(\"\", official=False)\n",
    "    emotion_encoding.new_encoding(mode=encoding_mode, mean_centered=False, official=False)\n",
    "    if(encoding_mode == \"bert\"):\n",
    "        x,y,_,_ = utils.project_points_onto_axes(emotion_encoding.bert_unofficial_embedding, X_low, X_high, Y_low, Y_high)\n",
    "    elif(encoding_mode == \"fasttext\"):\n",
    "        x,y,_,_ = utils.project_points_onto_axes(emotion_encoding.fasttext_unofficial_embedding, X_low, X_high, Y_low, Y_high)        \n",
    "    elif(encoding_mode == \"roberta\"):\n",
    "        x,y,_,_ = utils.project_points_onto_axes(emotion_encoding.roberta_unofficial_embedding, X_low, X_high, Y_low, Y_high)\n",
    "\n",
    "    x_avg, y_avg, emotion_labels = get_averaged_points(emotion_encoding, x, y)\n",
    "   \n",
    "    x_axis,y_axis,_,_ = utils.project_points_onto_axes([X_low, X_high, Y_low, Y_high], X_low, X_high, Y_low, Y_high)\n",
    "    axis_labels = [x_category_low, x_category_high, y_category_low, y_category_high]\n",
    "\n",
    "    # origin_x, origin_y = utils.line_intersection(x_axis, y_axis)\n",
    "    # x_avg -= origin_x\n",
    "    # y_avg -= origin_y\n",
    "    # x_axis -= origin_x\n",
    "    # y_axis -= origin_y\n",
    "\n",
    "    if(return_points):\n",
    "        return([x_avg, y_avg, emotion_labels])\n",
    "    else:\n",
    "        plt.figure(figsize=(7, 7))\n",
    "        plt.title(plot_labels[0])\n",
    "        plt.xlabel(plot_labels[1])\n",
    "        plt.ylabel(plot_labels[2])\n",
    "    \n",
    "        plt.scatter(0,0)\n",
    "        plt.annotate(\"(0,0)\", (0,0))\n",
    "\n",
    "        plt.scatter(x_avg, y_avg)\n",
    "        for i, emotion in enumerate(emotion_labels):\n",
    "            plt.annotate(emotion, (x_avg[i], y_avg[i]))\n",
    "        \n",
    "        plt.scatter(x_axis, y_axis)\n",
    "        for i, emotion in enumerate(axis_labels):\n",
    "            plt.annotate(emotion, (x_axis[i], y_axis[i]))\n",
    "        \n",
    "        # radius = np.average([abs(x_axis[0]), x_axis[1], abs(y_axis[2]), y_axis[3]])\n",
    "        # ax = plt.add_subplot()\n",
    "        # circle1 = patches.Circle((0, 0), radius, color='g', fill=False)\n",
    "        # ax.add_patch(circle1)\n",
    "        # ax.axis('equal')\n",
    "\n",
    "        plt.grid()\n",
    "        return([x_avg, y_avg, emotion_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_x, sbert_y, sbert_labels = \\\n",
    "make_plot(axis_file='VA_Russell_English',\n",
    "          emotion_file='English',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"bert\",\n",
    "          plot_labels=[\"English SBERT embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "multi_x, multi_y, multi_labels = \\\n",
    "make_plot(axis_file='VA_Russell_English',\n",
    "          emotion_file='English',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"roberta\",\n",
    "          roberta_model_name=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "          plot_labels=[\"English RoBERTa-XLM embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "get_distances(multi_x, multi_y, sbert_x, sbert_y, sbert_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_x, sbert_y, sbert_labels = \\\n",
    "make_plot(axis_file='VA_Russell_Chinese',        \n",
    "          emotion_file='Chinese',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"bert\",\n",
    "          plot_labels=[\"Chinese SBERT embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "multi_x, multi_y, multi_labels = \\\n",
    "make_plot(axis_file='VA_Russell_Chinese',\n",
    "          emotion_file='Chinese',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"roberta\",\n",
    "          roberta_model_name=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "          plot_labels=[\"Chinese RoBERTa-XLM embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "get_distances(multi_x, multi_y, sbert_x, sbert_y, sbert_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_x, sbert_y, sbert_labels = \\\n",
    "make_plot(axis_file='VA_Russell_Japanese',\n",
    "          emotion_file='Japanese',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"bert\",\n",
    "          plot_labels=[\"Japanese SBERT embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "multi_x, multi_y, multi_labels = \\\n",
    "make_plot(axis_file='VA_Russell_Japanese',\n",
    "          emotion_file='Japanese',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"roberta\",\n",
    "          roberta_model_name=\"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "          plot_labels=[\"Japanese RoBERTa-XLM embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "get_distances(multi_x, multi_y, sbert_x, sbert_y, sbert_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_x, multi_y, multi_labels = \\\n",
    "make_plot(axis_file='VA_Russell_Spanish',\n",
    "          emotion_file='Spanish',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"roberta\",\n",
    "          roberta_model_name=\"xlm-roberta-base\",\n",
    "          plot_labels=[\"Spanish RoBERTa-XLM embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "mono_x, mono_y, mono_labels = \\\n",
    "make_plot(axis_file='VA_Russell_Spanish',\n",
    "          emotion_file='Spanish',\n",
    "          emotion_filepath=\"Ekman_emotions/Ekman/\",\n",
    "          x_category_high=\"Positive valence\",\n",
    "          x_category_low=\"Negative valence\",\n",
    "          y_category_high=\"High arousal\",\n",
    "          y_category_low=\"Low arousal\",\n",
    "          encoding_mode=\"roberta\",\n",
    "          roberta_model_name=\"bertin-project/bertin-roberta-base-spanish\",\n",
    "          plot_labels=[\"Spanish RoBERTa embeddings on the Valence/Arousal Plane[Russell]\", \"Valence Dimension\", \"Arousal Dimension\"]\n",
    "          )\n",
    "\n",
    "get_distances(multi_x, multi_y, mono_x, mono_y, mono_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shreya_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "91463280d8781b4327168e6aed37b9922ec5e51ac75b06b77d3a30bc9c56392e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
